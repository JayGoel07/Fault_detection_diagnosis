{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10978920,"sourceType":"datasetVersion","datasetId":6832125}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install e2cnn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-18T05:46:31.068035Z","iopub.execute_input":"2025-02-18T05:46:31.068281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Function to load images from folder structure and flatten for Naive Bayes\ndef load_images_and_flatten(folder_path, label):\n    X, y = [], []\n    for filename in os.listdir(folder_path):\n        img_path = os.path.join(folder_path, filename)\n        img = cv2.imread(img_path)\n        if img is not None:\n            img = cv2.resize(img, (224, 224))  # Resize to 224x224\n            img = img.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n            X.append(img.flatten())  # Flatten the image to a 1D array\n            y.append(label)\n    return np.array(X), np.array(y)\n\n# Define folder paths for each class\nfolder_paths = {\n    'fault_A': '/kaggle/input/btp-dataset/btp_dataset/faulta_noise_20dB',\n    'fault_B': '/kaggle/input/btp-dataset/btp_dataset/faultb_noise_20dB',\n    'fault_C': '/kaggle/input/btp-dataset/btp_dataset/faultc_noise_20dB',\n    'healthy': '/kaggle/input/btp-dataset/btp_dataset/healthy_noise_20dB'\n}\n\n# Initialize lists for training and validation data\nX_train_total, y_train_total, X_val_total, y_val_total = [], [], [], []\n\n# Loop to perform 70/30 split for each folder\nfor class_label, folder_path in folder_paths.items():\n    X, y = load_images_and_flatten(folder_path, class_label)\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    X_train_total.append(X_train)\n    y_train_total.append(y_train)\n    X_val_total.append(X_val)\n    y_val_total.append(y_val)\n\n# Combine training and validation data\nX_train_total = np.concatenate(X_train_total)\ny_train_total = np.concatenate(y_train_total)\nX_val_total = np.concatenate(X_val_total)\ny_val_total = np.concatenate(y_val_total)\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_train_total = label_encoder.fit_transform(y_train_total)\ny_val_total = label_encoder.transform(y_val_total)\n\n# Standardize data\nscaler = StandardScaler()\nX_train_total = scaler.fit_transform(X_train_total)\nX_val_total = scaler.transform(X_val_total)\n\n# Train the Naive Bayes classifier\nnb_model = GaussianNB()\nnb_model.fit(X_train_total, y_train_total)\n\n# Evaluate the model\ny_val_pred = nb_model.predict(X_val_total)\naccuracy = accuracy_score(y_val_total, y_val_pred)\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n\n# Classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_val_total, y_val_pred, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:06:18.119376Z","iopub.execute_input":"2025-03-10T09:06:18.119659Z","iopub.status.idle":"2025-03-10T09:08:09.979413Z","shell.execute_reply.started":"2025-03-10T09:06:18.119638Z","shell.execute_reply":"2025-03-10T09:08:09.978563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Function to load images from folder structure and flatten for SVM\ndef load_images_and_flatten(folder_path, label):\n    X, y = [], []\n    for filename in os.listdir(folder_path):\n        img_path = os.path.join(folder_path, filename)\n        img = cv2.imread(img_path)\n        if img is not None:\n            img = cv2.resize(img, (224, 224))  # Resize to 224x224\n            img = img.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n            X.append(img.flatten())  # Flatten the image to a 1D array\n            y.append(label)\n    return np.array(X), np.array(y)\n\n# Define folder paths for each class\nfolder_paths = {\n    'fault_A': '/kaggle/input/btp-dataset/btp_dataset/faulta',\n    'fault_B': '/kaggle/input/btp-dataset/btp_dataset/faultb',\n    'fault_C': '/kaggle/input/btp-dataset/btp_dataset/faultc',\n    'healthy': '/kaggle/input/btp-dataset/btp_dataset/healthy'\n}\n\n# Initialize lists for training and validation data\nX_train_total, y_train_total, X_val_total, y_val_total = [], [], [], []\n\n# Loop to perform 70/30 split for each folder\nfor class_label, folder_path in folder_paths.items():\n    X, y = load_images_and_flatten(folder_path, class_label)\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    X_train_total.append(X_train)\n    y_train_total.append(y_train)\n    X_val_total.append(X_val)\n    y_val_total.append(y_val)\n\n# Combine training and validation data\nX_train_total = np.concatenate(X_train_total)\ny_train_total = np.concatenate(y_train_total)\nX_val_total = np.concatenate(X_val_total)\ny_val_total = np.concatenate(y_val_total)\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_train_total = label_encoder.fit_transform(y_train_total)\ny_val_total = label_encoder.transform(y_val_total)\n\n# Standardize data\nscaler = StandardScaler()\nX_train_total = scaler.fit_transform(X_train_total)\nX_val_total = scaler.transform(X_val_total)\n\n# Train the SVM classifier\nsvm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)  # RBF kernel with scaling\n# c Mathematically, it controls the penalty for misclassified point\nsvm_model.fit(X_train_total, y_train_total)\n\n# Evaluate the model\ny_val_pred = svm_model.predict(X_val_total)\naccuracy = accuracy_score(y_val_total, y_val_pred)\nprint(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n\n# Classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_val_total, y_val_pred, target_names=label_encoder.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T08:21:17.561212Z","iopub.execute_input":"2025-03-11T08:21:17.561413Z","iopub.status.idle":"2025-03-11T08:21:18.640149Z","shell.execute_reply.started":"2025-03-11T08:21:17.561392Z","shell.execute_reply":"2025-03-11T08:21:18.638600Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-271bc5cef1be>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Loop to perform 70/30 split for each folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolder_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-271bc5cef1be>\u001b[0m in \u001b[0;36mload_images_and_flatten\u001b[0;34m(folder_path, label)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images_and_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/btp-dataset/btp_dataset/faulta'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/btp-dataset/btp_dataset/faulta'","output_type":"error"}],"execution_count":1}]}